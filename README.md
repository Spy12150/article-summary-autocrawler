# Semiconductor News Scraper & Analyzer

A robust, modular Python tool for scraping semiconductor industry news and analyzing sentiment using LLM processing.

## ğŸ—ï¸ **Architecture**

```
Phase 1: News Scraping          Phase 2: LLM Processing
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web Scraping         â”‚     â”‚   Sentiment Analysis    â”‚
â”‚                         â”‚     â”‚                         â”‚
â”‚ â€¢ Trafilatura           â”‚â”€â”€â”€â”€â–¶â”‚ â€¢ DeepSeek-R1 LLM      â”‚
â”‚ â€¢ HTML Fallback        â”‚     â”‚ â€¢ JSON Summaries       â”‚
â”‚ â€¢ Playwright            â”‚     â”‚ â€¢ Progress Tracking     â”‚
â”‚ â€¢ Google Search         â”‚     â”‚ â€¢ Error Handling        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                               â”‚
           â–¼                               â–¼
    data/article_dataN.json         data/articles_processed.json
```

## ğŸš€ **Quick Start**

### **1. Setup**
```bash
git clone <repo-url>
cd "Innosci Internship Projects"
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

### **2. Configure API Keys**
```bash
cp config.example.py config.py
# Edit config.py with your actual API keys
```

### **3. Run Pipeline**
```bash
# Scrape articles
python main.py

# Process with LLM
python process_articles.py
```

## ğŸ”’ **Security & API Key Management**

### **âœ… What We Do (Secure)**
- API keys stored in `config.py` (gitignored)
- Example template in `config.example.py` (committed)
- Environment variable fallbacks
- Clear separation of code and credentials

### **âŒ What We Avoid**
- Hardcoded API keys in source code
- Committing sensitive credentials
- Sharing keys in plain text

### **File Structure**
```
config.py          â† Your actual API keys (NEVER commit)
config.example.py  â† Template for others (safe to commit)
.gitignore         â† Excludes config.py from git
```

### **Setup for New Environments**
```bash
# 1. Copy template
cp config.example.py config.py

# 2. Edit with real keys
nano config.py

# 3. Verify it's gitignored
git status  # config.py should not appear
```

## ğŸ“ **Project Structure**

```
â”œâ”€â”€ main.py                     # Phase 1: News scraping
â”œâ”€â”€ process_articles.py         # Phase 2: LLM processing
â”œâ”€â”€ google_search.py           # Google Custom Search integration
â”œâ”€â”€ config.py                  # API keys (gitignored)
â”œâ”€â”€ config.example.py          # Template for API keys
â”œâ”€â”€ requirements.txt           # Dependencies
â”œâ”€â”€ .gitignore                # Git exclusions
â”œâ”€â”€ SETUP.md                  # Deployment guide
â”œâ”€â”€ TROUBLESHOOTING.md        # Common issues
â”œâ”€â”€ README_PHASE2.md          # Detailed Phase 2 docs
â”‚
â”œâ”€â”€ crawlers/                 # Scraping modules
â”‚   â”œâ”€â”€ trafilatura_crawler.py
â”‚   â”œâ”€â”€ playwright_crawler.py
â”‚   â””â”€â”€ html_fallback_crawler.py
â”‚
â”œâ”€â”€ data/                     # Output files (gitignored)
â”‚   â”œâ”€â”€ article_data1.json    # Raw scraped articles
â”‚   â””â”€â”€ articles_processed.json # LLM-analyzed articles
â”‚
â””â”€â”€ downloaded_htmls/         # Raw HTML cache (gitignored)
```

## ğŸ› ï¸ **Features**

### **Phase 1: Web Scraping**
- **Multi-method approach**: Trafilatura â†’ HTML fallback â†’ Playwright
- **Google search integration**: Find news sites by keywords
- **Smart filtering**: Content length, headline validation
- **Robust error handling**: Graceful failures, retry logic
- **Progress tracking**: Per-site statistics

### **Phase 2: LLM Processing**
- **Sentiment analysis**: Positive/neutral/negative classification
- **Summarization**: Concise 1-3 sentence summaries
- **Retry logic**: Exponential backoff for network issues
- **Mock mode**: Testing without real LLM endpoint
- **Batch processing**: Progress bars for large datasets

## ğŸŒ **Network Requirements**

### **For Full Functionality:**
- Internet access (scraping)
- Access to `10.30.15.111:8080` (internal LLM)
- Google Custom Search API access

### **For Development/Testing:**
- Use `--endpoint 'mock'` for offline testing
- Mock mode provides realistic sentiment analysis

## ğŸ“Š **Usage Examples**

### **Basic Scraping**
```bash
# Manual URL entry
python main.py
# Enter URLs: https://www.semiconductors.org/news-events/latest-news/

# Google search mode  
python main.py
# Choose option 2, search: "semiconductor industry news"
```

### **LLM Processing**
```bash
# Real LLM endpoint
python process_articles.py --input data/article_data1.json

# Mock mode (for testing)
python process_articles.py --endpoint 'mock' --input data/article_data1.json

# Custom settings
python process_articles.py \
    --input data/article_data9.json \
    --output data/custom_processed.json \
    --model "Deepseek-r1:32b"
```

### **Diagnostics**
```bash
# Test LLM endpoint connectivity
python test_connection.py

# Test processing pipeline
python test_processing.py

# See sample output format
python demo_processing.py
```

## ğŸ’° **Cost Estimation**

- **Internal LLM**: Free (if accessible)
- **OpenAI GPT-4o**: ~$0.0125 per article
- **Google Search**: ~$5 per 1000 queries

## ğŸš¨ **Important for GitHub**

### **Before Pushing to GitHub:**
1. âœ… Ensure `config.py` is in `.gitignore`
2. âœ… Verify no API keys in source code
3. âœ… Include `config.example.py` for others
4. âœ… Test that `git status` doesn't show `config.py`

### **For Deployment:**
1. ğŸ“ Clone repo on target machine
2. ğŸ“ Copy `config.example.py` to `config.py`
3. ğŸ”‘ Add real API keys to `config.py`
4. ğŸŒ Test network connectivity to LLM endpoint
5. ğŸƒ Run the pipeline

## ğŸ“š **Documentation**

- **[SETUP.md](SETUP.md)**: Deployment guide for new environments
- **[TROUBLESHOOTING.md](TROUBLESHOOTING.md)**: Common issues and solutions  
- **[README_PHASE2.md](README_PHASE2.md)**: Detailed Phase 2 documentation

## ğŸ¤ **Contributing**

When contributing:
1. Never commit `config.py` with real API keys
2. Update `config.example.py` if new keys are needed
3. Test both real and mock modes
4. Update documentation for new features

---

**âš¡ This approach is industry standard and will work perfectly for GitHub deployment!**
